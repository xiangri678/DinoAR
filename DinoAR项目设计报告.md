# DinoAR - 基于AR眼镜的恐龙元宇宙系统

## 1. 项目概述

本研究从某恐龙化石博物馆的实际需求出发，利用Unity游戏引擎和XREAL AR眼镜，开发了一款基于AR的互动展示软件，参观者能够身临其境地观察并操控3D恐龙。项目通过AR技术将虚拟信息以多媒体的形式叠加到现实世界场景中，为用户带来沉浸式体验。

### 1.1 研究背景

随着增强现实（AR）技术的高速发展，AR在教育、游戏、导航、零售等诸多领域展现出广阔的应用前景。内蒙古自治区素有"恐龙的故乡"之称，为了更好地保护和展示这些恐龙文化遗产，该地区建有多家专门的恐龙化石博物馆。然而，传统的静态展品和讲解方式难以充分调动参观者的兴趣和参与度。AR技术与传统文博的结合，为提升博物馆展示手段带来了新的契机。

### 1.2 研究目的

通过利用Unity游戏引擎和XREAL AR眼镜等先进技术，开发基于AR的互动展示软件，让参观者能直观地观察并控制3D恐龙的各种动作，身临其境地感受恐龙的体型、行为习性和生存环境。同时，探讨AR交互设计的理论与实践，总结设计经验和技术细节，为后续开发AR应用提供借鉴和指导。

## 2. 项目功能与目标

本项目旨在将恐龙模型应用到AR眼镜中，实现以下功能：

1. 在AR眼镜中展示恐龙模型，确保尺寸适中，便于用户完整观察
2. 为恐龙走动配备逼真的声音效果，包括脚步声和吼叫声
3. 实现平面识别、手势交互和视角跟随移动功能
4. 创建互动游戏体验，使用户通过AR与恐龙进行互动

### 2.1 硬件环境

- XREAL X AR眼镜
- 支持的Android手机（如OPPO Find X5）

## 3. 研究方法

1. **文献调研**：收集和研究AR技术发展现状、交互设计理论、Unity引擎AR开发技术及AR眼镜硬件架构等
2. **需求分析**：考虑目标用户群体，明确功能需求、用户体验需求、界面需求以及AR交互需求
3. **系统设计**：设计系统架构，包括AR场景设计、UI界面设计、3D模型设计、交互逻辑设计等
4. **系统实现**：基于Unity引擎和NRSDK，采用C#编程语言实现各个模块
5. **测试与优化**：进行系统功能测试和交互体验测试，持续优化系统性能和交互流畅度

## 4. 研究过程

### 4.1 学习C#与Unity

- **安装和配置Unity**：安装Unity，学习创建新项目和导入资源
- **学习基本概念**：熟悉Unity的场景、游戏对象、组件、材质和着色器等概念
- **C#编程**：学习C#基础语法和高级特性（面向对象、容器、泛型、委托、闭包、反射、异常等）
- **官方教程**：学习Unity Essential路径和Junior Programmer课程

### 4.2 学习AR开发

- **AR基础知识**：学习AR的基本原理，包括跟踪、识别、虚拟对象的放置等
- **NRSDK**：学习如何集成NRSDK到Unity项目中
- **API学习**：了解输入方式、平面检测、手势追踪、运动追踪、深度网、空间锚、用户界面等功能

### 4.3 开发DinoAR应用

- **设计和构建AR场景**：规划功能，创建适用于AR的3D模型、纹理和场景
- **编写C#脚本**：处理应用程序的逻辑、用户输入和AR环境交互
- **测试和调试**：在AR眼镜上进行多场景测试，解决各种问题

## 5. 技术架构

游戏中出现的对象主要包括恐龙、钻石和准星。恐龙和钻石分别对应一个Manager脚本，实现其初始化。在游戏运行过程中，三者各自对应一个Behaviour脚本控制其运动状态。

![技术架构图](/images/技术架构图.png)

### 5.1 技术概述

#### 5.1.1 平面检测

通过调用`NRFrame.GetTrackables<NRTrackablePlane>(m_NewPlanes, NRTrackableQueryFilter.New)`方法获取当前帧中新检测到的平面，并将新检测到的平面存储在列表中。对每个新检测到的平面实例化平面可视化预制件，将平面可视化对象与对应平面关联起来。

#### 5.1.2 准星追踪

`RecticleBehaviour`脚本根据手部输入或射线检测控制准星位置。根据手控制器的位置和方向进行物理射线检测，当射线碰撞到NRSDK识别的平面时，准星会被移动到碰撞点位置并激活。

#### 5.1.3 恐龙运动

`DinoBehaviour`脚本控制恐龙模型跟随准星移动，并在靠近特定目标时播放动画和音效。根据准星位置和恐龙当前位置的距离判断移动状态，计算朝向方向并平滑旋转和移动。当恐龙触碰到带有`GemBehaviour`组件的物体时，随机播放动画和音效。

![启动游戏](/images/启动游戏.png)

恐龙的音效由脚本RaptorSoundEffects管理。首先定义了一个AudioSource变量用于播放音效。然后，分别定义了用于不同类型音效的音频剪辑数组，比如growlClips用于咆哮音效，sniffClips用于嗅探音效等。音频剪辑数组中包含了多个不同的音频剪辑，用于随机播放。

每个音效类型都有对应的方法，目的是为了与动画进行一一对应。比如Growl方法用于播放咆哮音效，Sniff方法用于播放嗅探音效等。这些方法会从对应类型的音频剪辑数组中选择和动画对应的音频剪辑，并使用AudioSource的PlayOneShot方法播放该音频剪辑。

#### 5.1.4 钻石生成

`GemSpawner`脚本在平面上生成宝石。通过获取平面网格信息和三角形索引，在随机选定的三角形内生成随机点，转换到世界坐标系并修正高度。实例化宝石预制件并放置在随机位置。

#### 5.1.5 屏幕录制

`VideoCapture2LocalExample`脚本使用NRVideoCapture API实现视频录制功能，可配置分辨率、混合模式、音频状态等选项，录制完成后保存到应用的持久数据路径并插入设备相册。

## 6. 应用流程

1. APP启动自动开始进行平面检测
2. 检测到平面后，在平面上显示木板纹理

   ![检测到的平面](/images/木板材质.png)

3. 创建手部锚点和控制器射线锚点，进行手部和控制器检测
4. 在指向方向延伸射线，与检测到的虚拟平面碰撞时显示蓝色准星

   ![准星显示](/images/准星模型.png)

5. 点击手机触控板，在准星位置放置恐龙模型
6. 恐龙跟随准星移动，可在idle、walk模式间平滑切换
7. 在虚拟平面上随机生成钻石供用户捕获

   ![钻石生成](/images/启动游戏.png)

8. 成功捕获钻石后，恐龙随机做出动作并播放音效

   ![恐龙动作](/images/获取宝石.png)

9. 继续生成新钻石，循环互动过程

   ![互动过程](/images/游戏面板.png)

## 7. 遇到的问题与解决

### 7.1 恐龙模型运动时方向倾斜

**问题**：恐龙在静止时出现自动偏斜问题。  
**解决**：游戏对象重心问题和平面识别精度不足导致，需与建模师合作优化模型设计。

![恐龙模型倾斜](/images/恐龙倾斜问题.png)
### 7.2 恐龙模型静止时抖动

**问题**：恐龙在静止时出现"抽搐"现象。  
**解决**：尝试减小Unity容错值，保留动画数据，提高采样精度，但根本解决需优化3D模型骨骼结构。

### 7.3 运动动画不够自然

**问题**：动画转换不平滑。  
**解决**：调整进入走动作的速度和退出速度，但会导致一定动画延迟。

![恐龙模型抖动](/images/平滑动画.png)

### 7.4 平面检测精确度

**问题**：平面检测对光照和纹理要求高，复杂场景识别困难。  
**解决**：禁止竖直平面锚定，优选纹理明显的平面环境。

![平面检测](/images/仅限水平追踪.png)

### 7.5 设备适配与可用性

**问题**：AR眼镜与手机连接失败。  
**解决**：清理手机内存，降低系统负载可能恢复连接。

![设备适配](/images/手机不适配.png)

## 8. 总结与展望

通过研发，成功开发了基于Unity和AR眼镜的互动展示软件，用户可以在真实环境中观察3D恐龙的各种行为，并通过自然交互方式控制恐龙。该软件展现了Unity+NRSDK在AR领域的强大开发能力，为博物馆、科普教育提供了新型AR展示手段。

未来计划：
1. 进一步优化系统性能，充分利用NRSDK特性
2. 融合更多手势跟踪的交互玩法
3. 提出"AR小镇"概念，实现多用户AR互动体验
4. 探索AR技术在更多领域的应用